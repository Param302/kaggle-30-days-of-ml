{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0d0ccb",
   "metadata": {
    "papermill": {
     "duration": 0.01587,
     "end_time": "2021-09-01T01:36:15.102489",
     "exception": false,
     "start_time": "2021-09-01T01:36:15.086619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414d7451",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-01T01:36:15.143430Z",
     "iopub.status.busy": "2021-09-01T01:36:15.142781Z",
     "iopub.status.idle": "2021-09-01T01:36:16.705722Z",
     "shell.execute_reply": "2021-09-01T01:36:16.705122Z",
     "shell.execute_reply.started": "2021-09-01T01:35:53.111055Z"
    },
    "papermill": {
     "duration": 1.588906,
     "end_time": "2021-09-01T01:36:16.705877",
     "exception": false,
     "start_time": "2021-09-01T01:36:15.116971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7d3d4",
   "metadata": {
    "papermill": {
     "duration": 0.014094,
     "end_time": "2021-09-01T01:36:16.734665",
     "exception": false,
     "start_time": "2021-09-01T01:36:16.720571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1st model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train.csv`) for training and testing where folds = 5\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **Ordinal Encoding** on optuna_model_1 to get numerical values of categorical values\n",
    "##### **One Hot Encoding** on model_1 to get numerical values of categorical values\n",
    "##### **XGBoost** to make the model and predict validation data and test data n estimators=1000\n",
    "____________________________________________________________________________________________________\n",
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fc84ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:36:16.797489Z",
     "iopub.status.busy": "2021-09-01T01:36:16.795715Z",
     "iopub.status.idle": "2021-09-01T01:36:16.798164Z",
     "shell.execute_reply": "2021-09-01T01:36:16.798583Z",
     "shell.execute_reply.started": "2021-09-01T00:43:08.713007Z"
    },
    "papermill": {
     "duration": 0.049615,
     "end_time": "2021-09-01T01:36:16.798717",
     "exception": false,
     "start_time": "2021-09-01T01:36:16.749102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1st model\n",
    "def model_1():\n",
    "    train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "    test_preds_1 = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "    \n",
    "    # K-fold splitting where total folds = 5\n",
    "    train_data[\"kfold\"] = -1\n",
    "    Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "    for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "        train_data.loc[valid_index, \"kfold\"] = fold\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required models\n",
    "    num_cols = [col for col in train_data.columns if \"cont\" in col]\n",
    "    cat_cols = [col for col in train_data.columns if \"cat\" in col]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    model_1_train_data = train_data\n",
    "    model_1_test_data = test_data\n",
    "    test_data = test_data[useful_cols]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Target Encoding\n",
    "    # Iterate over categorical columns\n",
    "    for col in cat_cols:\n",
    "        \"\"\"\n",
    "        Based on each categorical column, one target fold is created\n",
    "        total 5 folds for one column\n",
    "        \"\"\"\n",
    "        temp_train = []\n",
    "        temp_test_target = None\n",
    "        for fold in range(5):\n",
    "            # making training data and validating data for each fold\n",
    "            X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "            X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "            \n",
    "            # getting the mean of training data target\n",
    "            mean_target = dict(X_train.groupby(col)[\"target\"].agg(\"median\"))\n",
    "\n",
    "            # adding the mean_target to X_valid (valid dataset of each fold)\n",
    "            X_valid.loc[:, f\"target_enc_{col}\"] = X_valid[col].map(mean_target)\n",
    "            temp_train.append(X_valid)\n",
    "            if (temp_test_target is None):\n",
    "                temp_test_target = test_data[col].map(mean_target)\n",
    "            else:\n",
    "                temp_test_target += test_data[col].map(mean_target)\n",
    "                \n",
    "        # getting the average of temporary test target on each column\n",
    "        temp_test_target /= 5\n",
    "        # adding the temporary test target to test data on each column (total=5)\n",
    "        test_data.loc[:, f\"target_enc_{col}\"] = temp_test_target\n",
    "\n",
    "        # setting training data as temp_train\n",
    "        train_data = pd.concat(temp_train)\n",
    "        \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required columns again\n",
    "    useful_cols = [col for col in train_data.columns if ((train_data[col].dtypes == \"int64\") or (train_data[col].dtypes ==\"float64\")) and (col not in (\"id\"))]\n",
    "    cat_cols = [col for col in train_data.columns if (train_data[col].dtypes == \"object\")]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    train_data = train_data[useful_cols]\n",
    "    test_data = test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # optuna model 1 for final model 1\n",
    "    def optuna_model_1(trial):\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # Setting required columns again\n",
    "        useful_cols = [col for col in model_1_train_data.columns if ((model_1_train_data[col].dtypes == \"int64\") or (model_1_train_data[col].dtypes ==\"float64\")) and (col != \"id\")]\n",
    "        cat_cols = [col for col in model_1_test_data.columns if (model_1_test_data[col].dtypes == \"object\")]\n",
    "        useful_cols = cat_cols + num_cols\n",
    "        train_data = model_1_train_data[useful_cols]\n",
    "        test_data = model_1_test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # making parameteres\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.5, log=True)\n",
    "        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        \n",
    "        fold = 0\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_1_train_data[model_1_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_1_train_data[model_1_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        # setting the target\n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        # setting the training data and validating data\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "\n",
    "        # making model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=learning_rate,\n",
    "            reg_lambda=reg_lambda,\n",
    "            reg_alpha=reg_alpha,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            max_depth=max_depth,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=50,\n",
    "        )\n",
    "        # fitting data into the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=300,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=1000)\n",
    "\n",
    "        # getting predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        # getting RMSE\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        return rmse\n",
    "    #==============================================================================================================================================================================#\n",
    "    # Optimizing optuna_model and getting best parameters\n",
    "    optuna_1 = optuna.create_study(direction=\"minimize\")\n",
    "    optuna_1.optimize(optuna_model_1, n_trials=5)\n",
    "    best_params_model_1 = optuna_1.best_params\n",
    "    #==============================================================================================================================================================================#\n",
    "    # final_model made by XGB Regressor\n",
    "    final_valid_predictions = {}\n",
    "    final_test_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_1_train_data[model_1_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_1_train_data[model_1_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        X_test = test_data.copy()\n",
    "\n",
    "        valid_ids = X_valid.id.values.tolist()\n",
    "        \n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## One Hot Encoding for categorical data\n",
    "        OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        OH_encoder.fit(X_train[cat_cols])\n",
    "        OH_X_train = OH_encoder.transform(X_train[cat_cols])\n",
    "        OH_X_valid = OH_encoder.transform(X_valid[cat_cols])\n",
    "        OH_X_test = OH_encoder.transform(X_test[cat_cols])\n",
    "\n",
    "        # Naming the one hot encoded columns\n",
    "        OH_X_train = pd.DataFrame(OH_X_train, columns=[f\"ohe_{i}\" for i in range(OH_X_train.shape[1])])\n",
    "        OH_X_valid = pd.DataFrame(OH_X_valid, columns=[f\"ohe_{i}\" for i in range(OH_X_valid.shape[1])])\n",
    "        OH_X_test = pd.DataFrame(OH_X_test, columns=[f\"ohe_{i}\" for i in range(OH_X_test.shape[1])])\n",
    "\n",
    "        # Adding one hot encoded columns to main data (training, validating, test)\n",
    "        X_train = pd.concat([X_train, OH_X_train], axis=1)\n",
    "        X_valid = pd.concat([X_valid, OH_X_valid], axis=1)\n",
    "        X_test = pd.concat([X_test, OH_X_test], axis=1)\n",
    "\n",
    "        # Dropping the categorical columns, as their one hot encoded columns are added to main data\n",
    "        X_train = X_train.drop(cat_cols, axis=1)\n",
    "        X_valid = X_valid.drop(cat_cols, axis=1)\n",
    "        X_test = X_test.drop(cat_cols, axis=1)\n",
    "\n",
    "        # making the model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=2000,\n",
    "            **best_params_model_1,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=50,\n",
    "        )\n",
    "        # fitting the data in the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=300,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=1000)\n",
    "\n",
    "        # getting valid predictions and test predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "        test_preds = model.predict(X_test)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n",
    "        final_test_predictions.append(test_preds)\n",
    "\n",
    "        # rmse on valid predictions\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    valid_preds_1 = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    valid_preds_1.columns = [\"id\", \"pred_1\"]\n",
    "    valid_preds_1.to_csv(\"train_preds_1.csv\", index=False)\n",
    "    \n",
    "    test_preds_1.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    test_preds_1.columns = [\"id\", \"pred_1\"]\n",
    "    test_preds_1.to_csv(\"test_preds_1.csv\", index=False)\n",
    "    return scores, test_preds_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abdf5cc",
   "metadata": {
    "papermill": {
     "duration": 0.014155,
     "end_time": "2021-09-01T01:36:16.827405",
     "exception": false,
     "start_time": "2021-09-01T01:36:16.813250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE and Test Predictions on model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e0469d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:36:16.861777Z",
     "iopub.status.busy": "2021-09-01T01:36:16.861265Z",
     "iopub.status.idle": "2021-09-01T01:38:33.379998Z",
     "shell.execute_reply": "2021-09-01T01:38:33.376814Z",
     "shell.execute_reply.started": "2021-09-01T00:43:09.170345Z"
    },
    "papermill": {
     "duration": 136.537992,
     "end_time": "2021-09-01T01:38:33.380337",
     "exception": false,
     "start_time": "2021-09-01T01:36:16.842345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:36:28,000]\u001b[0m A new study created in memory with name: no-name-fd9fca7e-d25d-46ce-ab47-f85042ff14f7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6.89149\n",
      "[846]\tvalidation_0-rmse:0.72126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:36:32,906]\u001b[0m Trial 0 finished with value: 0.7211777159433347 and parameters: {'learning_rate': 0.1147570270572494, 'reg_lambda': 6.825851382112473, 'reg_alpha': 3.213300893168289e-06, 'subsample': 0.10892909814702535, 'colsample_bytree': 0.46323340760229426, 'max_depth': 3}. Best is trial 0 with value: 0.7211777159433347.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.26166\n",
      "[1000]\tvalidation_0-rmse:0.71794\n",
      "[1086]\tvalidation_0-rmse:0.71808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:36:41,010]\u001b[0m Trial 1 finished with value: 0.7176918745026623 and parameters: {'learning_rate': 0.06664684744753252, 'reg_lambda': 0.018108864693262686, 'reg_alpha': 36.20447627410865, 'subsample': 0.8171198858875128, 'colsample_bytree': 0.9264069112538692, 'max_depth': 6}. Best is trial 1 with value: 0.7176918745026623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.08504\n",
      "[442]\tvalidation_0-rmse:0.73064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:36:54,492]\u001b[0m Trial 2 finished with value: 0.7235744320960131 and parameters: {'learning_rate': 0.08954578797888178, 'reg_lambda': 1.928061183994041, 'reg_alpha': 3.621485314970313e-07, 'subsample': 0.5615787273460423, 'colsample_bytree': 0.725498930130339, 'max_depth': 9}. Best is trial 1 with value: 0.7176918745026623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.43607\n",
      "[520]\tvalidation_0-rmse:0.72659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:37:18,523]\u001b[0m Trial 3 finished with value: 0.7240961981891074 and parameters: {'learning_rate': 0.044003648985582976, 'reg_lambda': 3.931013213625755e-05, 'reg_alpha': 7.990103809461327e-06, 'subsample': 0.32260766054084444, 'colsample_bytree': 0.32663613159565374, 'max_depth': 10}. Best is trial 1 with value: 0.7176918745026623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.49610\n",
      "[1000]\tvalidation_0-rmse:0.72160\n",
      "[1002]\tvalidation_0-rmse:0.72160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:37:29,725]\u001b[0m Trial 4 finished with value: 0.7209834010553372 and parameters: {'learning_rate': 0.03621325990966776, 'reg_lambda': 0.013281140637444693, 'reg_alpha': 0.0040249175840555386, 'subsample': 0.3514272455549661, 'colsample_bytree': 0.7301529090132135, 'max_depth': 7}. Best is trial 1 with value: 0.7176918745026623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.26166\n",
      "[1000]\tvalidation_0-rmse:0.71788\n",
      "[1076]\tvalidation_0-rmse:0.71805\n",
      "[0]\tvalidation_0-rmse:7.26499\n",
      "[1000]\tvalidation_0-rmse:0.72562\n",
      "[1125]\tvalidation_0-rmse:0.72585\n",
      "[0]\tvalidation_0-rmse:7.26102\n",
      "[1000]\tvalidation_0-rmse:0.72076\n",
      "[1215]\tvalidation_0-rmse:0.72103\n",
      "[0]\tvalidation_0-rmse:7.26746\n",
      "[1000]\tvalidation_0-rmse:0.72013\n",
      "[1117]\tvalidation_0-rmse:0.72031\n",
      "[0]\tvalidation_0-rmse:7.26718\n",
      "[1000]\tvalidation_0-rmse:0.71575\n",
      "[1142]\tvalidation_0-rmse:0.71590\n",
      "MSE: [0.7175903370259966, 0.7255340176048198, 0.7206253625231483, 0.7200180255998814, 0.7155452285583133]\n",
      "Test data predictions:             id    pred_1\n",
      "0            0  8.070074\n",
      "1            5  8.362631\n",
      "2           15  8.372488\n",
      "3           16  8.466038\n",
      "4           17  8.137090\n",
      "...        ...       ...\n",
      "199995  499987  8.085490\n",
      "199996  499990  8.414785\n",
      "199997  499991  8.434820\n",
      "199998  499994  8.084948\n",
      "199999  499995  7.998491\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model_1 MSE and test_predictions\n",
    "mse_1, final_preds_1 = model_1()\n",
    "print(f\"MSE: {mse_1}\\nTest data predictions: {final_preds_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ac0d3",
   "metadata": {
    "papermill": {
     "duration": 0.039733,
     "end_time": "2021-09-01T01:38:33.462409",
     "exception": false,
     "start_time": "2021-09-01T01:38:33.422676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2nd model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train.csv`) for training and testing where folds = 5\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **One Hot Encoding** on optuna_model_1 to get numerical values of categorical values\n",
    "##### **Ordinal Encoding** on model_1 to get numerical values of categorical values\n",
    "##### **XGB Regressor** to make the model and predict validation data and test data n estimators=5000\n",
    "____________________________________________________________________________________________________\n",
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7162201",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:38:33.570273Z",
     "iopub.status.busy": "2021-09-01T01:38:33.553232Z",
     "iopub.status.idle": "2021-09-01T01:38:33.588120Z",
     "shell.execute_reply": "2021-09-01T01:38:33.588716Z",
     "shell.execute_reply.started": "2021-09-01T00:44:59.164158Z"
    },
    "papermill": {
     "duration": 0.090143,
     "end_time": "2021-09-01T01:38:33.588912",
     "exception": false,
     "start_time": "2021-09-01T01:38:33.498769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2nd model\n",
    "def model_2():\n",
    "    train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "    test_preds_2 = sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "    \n",
    "    # K-fold splitting where total folds = 5\n",
    "    train_data[\"kfold\"] = -1\n",
    "    Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "    for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "        train_data.loc[valid_index, \"kfold\"] = fold\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required models\n",
    "    num_cols = [col for col in train_data.columns if \"cont\" in col]\n",
    "    cat_cols = [col for col in train_data.columns if \"cat\" in col]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    model_2_train_data = train_data\n",
    "    model_2_test_data = test_data\n",
    "    test_data = test_data[useful_cols]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Target Encoding\n",
    "    # Iterate over categorical columns\n",
    "    for col in cat_cols:\n",
    "        \"\"\"\n",
    "        Based on each categorical column, one target fold is created\n",
    "        total 5 folds for one column\n",
    "        \"\"\"\n",
    "        temp_train = []\n",
    "        temp_test_target = None\n",
    "        for fold in range(5):\n",
    "            # making training data and validating data for each fold\n",
    "            X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "            X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "            \n",
    "            # getting the mean of training data target\n",
    "            mean_target = dict(X_train.groupby(col)[\"target\"].agg(\"median\"))\n",
    "\n",
    "            # adding the mean_target to X_valid (valid dataset of each fold)\n",
    "            X_valid.loc[:, f\"target_enc_{col}\"] = X_valid[col].map(mean_target)\n",
    "            temp_train.append(X_valid)\n",
    "            if (temp_test_target is None):\n",
    "                temp_test_target = test_data[col].map(mean_target)\n",
    "            else:\n",
    "                temp_test_target += test_data[col].map(mean_target)\n",
    "                \n",
    "        # getting the average of temporary test target on each column\n",
    "        temp_test_target /= 5\n",
    "        # adding the temporary test target to test data on each column (total=5)\n",
    "        test_data.loc[:, f\"target_enc_{col}\"] = temp_test_target\n",
    "\n",
    "        # setting training data as temp_train\n",
    "        train_data = pd.concat(temp_train)\n",
    "        \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required columns again\n",
    "    useful_cols = [col for col in train_data.columns if ((train_data[col].dtypes == \"int64\") or (train_data[col].dtypes ==\"float64\")) and (col not in (\"id\"))]\n",
    "    cat_cols = [col for col in train_data.columns if (train_data[col].dtypes == \"object\")]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    train_data = train_data[useful_cols]\n",
    "    test_data = test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # optuna model 2 for final model 2\n",
    "    def optuna_model_2(trial):\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # Setting required columns again\n",
    "        useful_cols = [col for col in model_2_train_data.columns if ((model_2_train_data[col].dtypes == \"int64\") or (model_2_train_data[col].dtypes ==\"float64\")) and (col != \"id\")]\n",
    "        cat_cols = [col for col in model_2_test_data.columns if (model_2_test_data[col].dtypes == \"object\")]\n",
    "        useful_cols = cat_cols + num_cols\n",
    "        train_data = model_2_train_data[useful_cols]\n",
    "        test_data = model_2_test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # making parameteres\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.05, log=True)\n",
    "        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        \n",
    "        fold = 0\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_2_train_data[model_2_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_2_train_data[model_2_train_data.kfold == fold].reset_index(drop=True)\n",
    "        \n",
    "        X_test = test_data.copy()\n",
    "        \n",
    "        # setting the target\n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        # setting the training data and validating data\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## One Hot Encoding for categorical data\n",
    "        OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        OH_encoder.fit(X_train[cat_cols])\n",
    "        OH_X_train = OH_encoder.transform(X_train[cat_cols])\n",
    "        OH_X_valid = OH_encoder.transform(X_valid[cat_cols])\n",
    "\n",
    "        # Naming the one hot encoded columns\n",
    "        OH_X_train = pd.DataFrame(OH_X_train, columns=[f\"ohe_{i}\" for i in range(OH_X_train.shape[1])])\n",
    "        OH_X_valid = pd.DataFrame(OH_X_valid, columns=[f\"ohe_{i}\" for i in range(OH_X_valid.shape[1])])\n",
    "\n",
    "        # Adding one hot encoded columns to main data (training, validating, test)\n",
    "        X_train = pd.concat([X_train, OH_X_train], axis=1)\n",
    "        X_valid = pd.concat([X_valid, OH_X_valid], axis=1)\n",
    "\n",
    "        # Dropping the categorical columns, as their one hot encoded columns are added to main data\n",
    "        X_train = X_train.drop(cat_cols, axis=1)\n",
    "        X_valid = X_valid.drop(cat_cols, axis=1)\n",
    "\n",
    "        # making model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=5000,\n",
    "            learning_rate=learning_rate,\n",
    "            reg_lambda=reg_lambda,\n",
    "            reg_alpha=reg_alpha,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            max_depth=max_depth,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting data into the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=500,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=2000)\n",
    "\n",
    "        # getting predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        # getting RMSE\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        return rmse\n",
    "    #==============================================================================================================================================================================#\n",
    "    # Optimizing optuna_model and getting best parameters\n",
    "    optuna_2 = optuna.create_study(direction=\"minimize\")\n",
    "    optuna_2.optimize(optuna_model_2, n_trials=5)\n",
    "    best_params_model_2 = optuna_2.best_params\n",
    "    #==============================================================================================================================================================================#\n",
    "    # final_model made by XGB Regressor\n",
    "    final_valid_predictions = {}\n",
    "    final_test_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_2_train_data[model_2_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_2_train_data[model_2_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        X_test = test_data.copy()\n",
    "\n",
    "        valid_ids = X_valid.id.values.tolist()\n",
    "        \n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "        \n",
    "        ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "        X_test[cat_cols] = Ord_encoder.transform(X_test[cat_cols])\n",
    "\n",
    "        # making the model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=5000,\n",
    "            **best_params_model_2,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting the data in the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=500,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=2000)\n",
    "\n",
    "        # getting valid predictions and test predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "        test_preds = model.predict(X_test)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n",
    "        final_test_predictions.append(test_preds)\n",
    "\n",
    "        # rmse on valid predictions\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    valid_preds_2 = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    valid_preds_2.columns = [\"id\", \"pred_2\"]\n",
    "    valid_preds_2.to_csv(\"train_preds_2.csv\", index=False)\n",
    "    \n",
    "    test_preds_2.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    test_preds_2.columns = [\"id\", \"pred_2\"]\n",
    "    test_preds_2.to_csv(\"test_preds_2.csv\", index=False)\n",
    "    return scores, test_preds_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd6578f",
   "metadata": {
    "papermill": {
     "duration": 0.038433,
     "end_time": "2021-09-01T01:38:33.666368",
     "exception": false,
     "start_time": "2021-09-01T01:38:33.627935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE and Test Predictions on model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac00d091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:38:33.751487Z",
     "iopub.status.busy": "2021-09-01T01:38:33.750338Z",
     "iopub.status.idle": "2021-09-01T01:42:28.052337Z",
     "shell.execute_reply": "2021-09-01T01:42:28.052803Z",
     "shell.execute_reply.started": "2021-09-01T00:44:59.197753Z"
    },
    "papermill": {
     "duration": 234.347403,
     "end_time": "2021-09-01T01:42:28.052974",
     "exception": false,
     "start_time": "2021-09-01T01:38:33.705571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:38:42,138]\u001b[0m A new study created in memory with name: no-name-b332ef5c-d474-4db4-8622-4c7f60d82625\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.46870\n",
      "[2000]\tvalidation_0-rmse:0.72055\n",
      "[4000]\tvalidation_0-rmse:0.71731\n",
      "[4999]\tvalidation_0-rmse:0.71665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:39:00,109]\u001b[0m Trial 0 finished with value: 0.716648121574307 and parameters: {'learning_rate': 0.03977377364433992, 'reg_lambda': 4.411299029154334e-06, 'reg_alpha': 0.0001810029330122166, 'subsample': 0.822184849960225, 'colsample_bytree': 0.3429127494185461, 'max_depth': 2}. Best is trial 0 with value: 0.716648121574307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.66283\n",
      "[2000]\tvalidation_0-rmse:0.71789\n",
      "[4000]\tvalidation_0-rmse:0.71625\n",
      "[4999]\tvalidation_0-rmse:0.71615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:39:28,994]\u001b[0m Trial 1 finished with value: 0.7161394154357016 and parameters: {'learning_rate': 0.01457554904308877, 'reg_lambda': 1.0992630150897692e-05, 'reg_alpha': 8.34628164572927e-07, 'subsample': 0.8711763606429522, 'colsample_bytree': 0.27848310455534064, 'max_depth': 5}. Best is trial 1 with value: 0.7161394154357016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.67449\n",
      "[2000]\tvalidation_0-rmse:0.71993\n",
      "[4000]\tvalidation_0-rmse:0.71738\n",
      "[4999]\tvalidation_0-rmse:0.71690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:39:52,634]\u001b[0m Trial 2 finished with value: 0.7168974430479758 and parameters: {'learning_rate': 0.013063915233843178, 'reg_lambda': 4.9083797513294517e-05, 'reg_alpha': 6.268155107812823e-08, 'subsample': 0.4368924520929911, 'colsample_bytree': 0.41471170215563125, 'max_depth': 4}. Best is trial 1 with value: 0.7161394154357016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.60661\n",
      "[2000]\tvalidation_0-rmse:0.72090\n",
      "[4000]\tvalidation_0-rmse:0.71832\n",
      "[4999]\tvalidation_0-rmse:0.71776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:40:13,394]\u001b[0m Trial 3 finished with value: 0.7177591065596528 and parameters: {'learning_rate': 0.021876088494678037, 'reg_lambda': 0.013567567916936871, 'reg_alpha': 70.74015350955486, 'subsample': 0.5360129060849486, 'colsample_bytree': 0.55202670782887, 'max_depth': 3}. Best is trial 1 with value: 0.7161394154357016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.56972\n",
      "[2000]\tvalidation_0-rmse:0.72859\n",
      "[4000]\tvalidation_0-rmse:0.72612\n",
      "[4999]\tvalidation_0-rmse:0.72527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:40:28,636]\u001b[0m Trial 4 finished with value: 0.7252652354124913 and parameters: {'learning_rate': 0.02666227099329454, 'reg_lambda': 6.44329044918662e-06, 'reg_alpha': 2.4751915432790983, 'subsample': 0.5863318545554217, 'colsample_bytree': 0.9131362150130748, 'max_depth': 1}. Best is trial 1 with value: 0.7161394154357016.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.66284\n",
      "[2000]\tvalidation_0-rmse:0.71777\n",
      "[4000]\tvalidation_0-rmse:0.71622\n",
      "[4999]\tvalidation_0-rmse:0.71607\n",
      "[0]\tvalidation_0-rmse:7.66605\n",
      "[2000]\tvalidation_0-rmse:0.72569\n",
      "[4000]\tvalidation_0-rmse:0.72407\n",
      "[4999]\tvalidation_0-rmse:0.72391\n",
      "[0]\tvalidation_0-rmse:7.66214\n",
      "[2000]\tvalidation_0-rmse:0.72129\n",
      "[4000]\tvalidation_0-rmse:0.71969\n",
      "[4999]\tvalidation_0-rmse:0.71948\n",
      "[0]\tvalidation_0-rmse:7.66851\n",
      "[2000]\tvalidation_0-rmse:0.72048\n",
      "[4000]\tvalidation_0-rmse:0.71906\n",
      "[4999]\tvalidation_0-rmse:0.71896\n",
      "[0]\tvalidation_0-rmse:7.66833\n",
      "[2000]\tvalidation_0-rmse:0.71591\n",
      "[4000]\tvalidation_0-rmse:0.71421\n",
      "[4999]\tvalidation_0-rmse:0.71401\n",
      "MSE: [0.7160550903886324, 0.7239131575714605, 0.7194784348760122, 0.7189435754938459, 0.714003905062061]\n",
      "Test data predictions:             id    pred_2\n",
      "0            0  8.082083\n",
      "1            5  8.389063\n",
      "2           15  8.400261\n",
      "3           16  8.462927\n",
      "4           17  8.182848\n",
      "...        ...       ...\n",
      "199995  499987  8.081489\n",
      "199996  499990  8.416911\n",
      "199997  499991  8.438597\n",
      "199998  499994  8.136818\n",
      "199999  499995  7.897868\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model_2 MSE and test_predictions\n",
    "mse_2, final_preds_2 = model_2()\n",
    "print(f\"MSE: {mse_2}\\nTest data predictions: {final_preds_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a46bed",
   "metadata": {
    "papermill": {
     "duration": 0.034654,
     "end_time": "2021-09-01T01:42:28.122876",
     "exception": false,
     "start_time": "2021-09-01T01:42:28.088222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3rd model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train.csv`) for training and testing where folds = 5\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **One Hot Encoding** on optuna_model_1 to get numerical values of categorical values\n",
    "##### **Ordinal Encoding** on model_1 to get numerical values of categorical values\n",
    "##### **XGB Regressor** to make the model and predict validation data and test data n estimators=10000\n",
    "____________________________________________________________________________________________________\n",
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f009168",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:42:28.221690Z",
     "iopub.status.busy": "2021-09-01T01:42:28.217561Z",
     "iopub.status.idle": "2021-09-01T01:42:28.223776Z",
     "shell.execute_reply": "2021-09-01T01:42:28.224171Z",
     "shell.execute_reply.started": "2021-09-01T00:51:56.647519Z"
    },
    "papermill": {
     "duration": 0.066565,
     "end_time": "2021-09-01T01:42:28.224308",
     "exception": false,
     "start_time": "2021-09-01T01:42:28.157743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3rd model\n",
    "def model_3():\n",
    "    train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "    test_preds_3 = sample_submission_3 = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "    \n",
    "    # K-fold splitting where total folds = 5\n",
    "    train_data[\"kfold\"] = -1\n",
    "    Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "    for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "        train_data.loc[valid_index, \"kfold\"] = fold\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required models\n",
    "    num_cols = [col for col in train_data.columns if \"cont\" in col]\n",
    "    cat_cols = [col for col in train_data.columns if \"cat\" in col]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    model_3_train_data = train_data\n",
    "    model_3_test_data = test_data\n",
    "    test_data = test_data[useful_cols]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Target Encoding\n",
    "    # Iterate over categorical columns\n",
    "    for col in cat_cols:\n",
    "        \"\"\"\n",
    "        Based on each categorical column, one target fold is created\n",
    "        total 5 folds for one column\n",
    "        \"\"\"\n",
    "        temp_train = []\n",
    "        temp_test_target = None\n",
    "        for fold in range(5):\n",
    "            # making training data and validating data for each fold\n",
    "            X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "            X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "            \n",
    "            # getting the mean of training data target\n",
    "            mean_target = dict(X_train.groupby(col)[\"target\"].agg(\"median\"))\n",
    "\n",
    "            # adding the mean_target to X_valid (valid dataset of each fold)\n",
    "            X_valid.loc[:, f\"target_enc_{col}\"] = X_valid[col].map(mean_target)\n",
    "            temp_train.append(X_valid)\n",
    "            if (temp_test_target is None):\n",
    "                temp_test_target = test_data[col].map(mean_target)\n",
    "            else:\n",
    "                temp_test_target += test_data[col].map(mean_target)\n",
    "                \n",
    "        # getting the average of temporary test target on each column\n",
    "        temp_test_target /= 5\n",
    "        # adding the temporary test target to test data on each column (total=5)\n",
    "        test_data.loc[:, f\"target_enc_{col}\"] = temp_test_target\n",
    "\n",
    "        # setting training data as temp_train\n",
    "        train_data = pd.concat(temp_train)\n",
    "        \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required columns again\n",
    "    useful_cols = [col for col in train_data.columns if ((train_data[col].dtypes == \"int64\") or (train_data[col].dtypes ==\"float64\")) and (col not in (\"id\"))]\n",
    "    cat_cols = [col for col in train_data.columns if (train_data[col].dtypes == \"object\")]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    train_data = train_data[useful_cols]\n",
    "    test_data = test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # optuna model 3 for final model 3\n",
    "    def optuna_model_3(trial):\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # Setting required columns again\n",
    "        useful_cols = [col for col in model_3_train_data.columns if ((model_3_train_data[col].dtypes == \"int64\") or (model_3_train_data[col].dtypes ==\"float64\")) and (col != \"id\")]\n",
    "        cat_cols = [col for col in model_3_test_data.columns if (model_3_test_data[col].dtypes == \"object\")]\n",
    "        useful_cols = cat_cols + num_cols\n",
    "        train_data = model_3_train_data[useful_cols]\n",
    "        test_data = model_3_test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # making parameteres\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.5, log=True)\n",
    "        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        \n",
    "        fold = 0\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_3_train_data[model_3_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_3_train_data[model_3_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        # setting the target\n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        # setting the training data and validating data\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "\n",
    "        # making model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=10000,\n",
    "            learning_rate=learning_rate,\n",
    "            reg_lambda=reg_lambda,\n",
    "            reg_alpha=reg_alpha,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            max_depth=max_depth,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting data into the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=1000,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=5000)\n",
    "\n",
    "        # getting predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        # getting RMSE\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        return rmse\n",
    "    #==============================================================================================================================================================================#\n",
    "    \n",
    "    # Optimizing optuna_model and getting best parameters\n",
    "    optuna_3 = optuna.create_study(direction=\"minimize\")\n",
    "    optuna_3.optimize(optuna_model_3, n_trials=5)\n",
    "    best_params_model_3 = optuna_3.best_params\n",
    "    #==============================================================================================================================================================================#\n",
    "    \n",
    "    # final_model made by XGB Regressor\n",
    "    final_valid_predictions = {}\n",
    "    final_test_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_3_train_data[model_3_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_3_train_data[model_3_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        X_test = test_data.copy()\n",
    "\n",
    "        valid_ids = X_valid.id.values.tolist()\n",
    "        \n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "         ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "        X_test[cat_cols] = Ord_encoder.transform(X_test[cat_cols])\n",
    "\n",
    "        # making the model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=10000,\n",
    "            **best_params_model_3,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting the data in the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=1000,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=5000)\n",
    "\n",
    "        # getting valid predictions and test predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "        test_preds = model.predict(X_test)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n",
    "        final_test_predictions.append(test_preds)\n",
    "\n",
    "        # rmse on valid predictions\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    valid_preds_3 = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    valid_preds_3.columns = [\"id\", \"pred_3\"]\n",
    "    valid_preds_3.to_csv(\"train_preds_3.csv\", index=False)\n",
    "    \n",
    "    test_preds_3.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    test_preds_3.columns = [\"id\", \"pred_3\"]\n",
    "    test_preds_3.to_csv(\"test_preds_3.csv\", index=False)\n",
    "    return scores, test_preds_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058b4df",
   "metadata": {
    "papermill": {
     "duration": 0.034472,
     "end_time": "2021-09-01T01:42:28.293583",
     "exception": false,
     "start_time": "2021-09-01T01:42:28.259111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE and Test Predictions on model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f440c589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:42:28.366946Z",
     "iopub.status.busy": "2021-09-01T01:42:28.366418Z",
     "iopub.status.idle": "2021-09-01T01:45:58.515136Z",
     "shell.execute_reply": "2021-09-01T01:45:58.515703Z",
     "shell.execute_reply.started": "2021-09-01T00:51:56.679194Z"
    },
    "papermill": {
     "duration": 210.18743,
     "end_time": "2021-09-01T01:45:58.515902",
     "exception": false,
     "start_time": "2021-09-01T01:42:28.328472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:42:36,477]\u001b[0m A new study created in memory with name: no-name-070f35b2-0d27-44a8-9414-60f66e46974c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.93026\n",
      "[1044]\tvalidation_0-rmse:0.78538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:42:53,200]\u001b[0m Trial 0 finished with value: 0.7234899167795706 and parameters: {'learning_rate': 0.3704086420738438, 'reg_lambda': 58.44132678232211, 'reg_alpha': 3.436644860302557, 'subsample': 0.4741806916865723, 'colsample_bytree': 0.2162045932217823, 'max_depth': 8}. Best is trial 0 with value: 0.7234899167795706.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.46218\n",
      "[1907]\tvalidation_0-rmse:0.71786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:43:10,465]\u001b[0m Trial 1 finished with value: 0.7168681313976885 and parameters: {'learning_rate': 0.04062768193511658, 'reg_lambda': 10.06719904269574, 'reg_alpha': 11.079171880172636, 'subsample': 0.5040656301684638, 'colsample_bytree': 0.28190955566916, 'max_depth': 7}. Best is trial 1 with value: 0.7168681313976885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.67652\n",
      "[5000]\tvalidation_0-rmse:0.71707\n",
      "[5894]\tvalidation_0-rmse:0.71712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:43:36,072]\u001b[0m Trial 2 finished with value: 0.7170435206401045 and parameters: {'learning_rate': 0.012797488456053238, 'reg_lambda': 1.3190033017972656e-07, 'reg_alpha': 0.0012425080786613982, 'subsample': 0.9347587316738429, 'colsample_bytree': 0.5545234943960127, 'max_depth': 5}. Best is trial 1 with value: 0.7168681313976885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6.80807\n",
      "[1176]\tvalidation_0-rmse:0.73234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:44:11,463]\u001b[0m Trial 3 finished with value: 0.7194809320263664 and parameters: {'learning_rate': 0.12555913631539878, 'reg_lambda': 5.0683845546986964e-08, 'reg_alpha': 2.827968746968803, 'subsample': 0.9998097181189507, 'colsample_bytree': 0.13613448200317219, 'max_depth': 10}. Best is trial 1 with value: 0.7168681313976885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:4.47806\n",
      "[1043]\tvalidation_0-rmse:0.77762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:44:19,756]\u001b[0m Trial 4 finished with value: 0.7243339131541159 and parameters: {'learning_rate': 0.4294271113748058, 'reg_lambda': 21.710833827518666, 'reg_alpha': 1.279712114236112e-07, 'subsample': 0.7143892197440618, 'colsample_bytree': 0.6666124639917888, 'max_depth': 6}. Best is trial 1 with value: 0.7168681313976885.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.46218\n",
      "[1908]\tvalidation_0-rmse:0.71787\n",
      "[0]\tvalidation_0-rmse:7.46545\n",
      "[2014]\tvalidation_0-rmse:0.72594\n",
      "[0]\tvalidation_0-rmse:7.46141\n",
      "[1997]\tvalidation_0-rmse:0.72106\n",
      "[0]\tvalidation_0-rmse:7.46787\n",
      "[1979]\tvalidation_0-rmse:0.72086\n",
      "[0]\tvalidation_0-rmse:7.46767\n",
      "[2142]\tvalidation_0-rmse:0.71634\n",
      "MSE: [0.7168681313976885, 0.724654647863053, 0.7199917763674756, 0.7195306230476601, 0.7150173920468939]\n",
      "Test data predictions:             id    pred_3\n",
      "0            0  8.110340\n",
      "1            5  8.352780\n",
      "2           15  8.397600\n",
      "3           16  8.441732\n",
      "4           17  8.148008\n",
      "...        ...       ...\n",
      "199995  499987  8.057126\n",
      "199996  499990  8.411471\n",
      "199997  499991  8.436836\n",
      "199998  499994  8.081011\n",
      "199999  499995  7.965829\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model_3 MSE and test_predictions\n",
    "mse_3, final_preds_3 = model_3()\n",
    "print(f\"MSE: {mse_3}\\nTest data predictions: {final_preds_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c80e7",
   "metadata": {
    "papermill": {
     "duration": 0.041698,
     "end_time": "2021-09-01T01:45:58.601997",
     "exception": false,
     "start_time": "2021-09-01T01:45:58.560299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`\n",
    "### Training predicted data\n",
    "* `train_pred_1.csv`\n",
    "* `train_pred_2.csv`\n",
    "* `train_pred_3.csv`\n",
    "### Test predicted data\n",
    "* `test_pred_1.csv`\n",
    "* `test_pred_2.csv`\n",
    "* `test_pred_3.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68958ccd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:45:58.693910Z",
     "iopub.status.busy": "2021-09-01T01:45:58.693348Z",
     "iopub.status.idle": "2021-09-01T01:46:01.071439Z",
     "shell.execute_reply": "2021-09-01T01:46:01.070883Z",
     "shell.execute_reply.started": "2021-09-01T01:33:30.218772Z"
    },
    "papermill": {
     "duration": 2.427113,
     "end_time": "2021-09-01T01:46:01.071583",
     "exception": false,
     "start_time": "2021-09-01T01:45:58.644470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "train_pred_1 = pd.read_csv(\"train_preds_1.csv\")\n",
    "train_pred_2 = pd.read_csv(\"train_preds_2.csv\")\n",
    "train_pred_3 = pd.read_csv(\"train_preds_3.csv\")\n",
    "\n",
    "test_pred_1 = pd.read_csv(\"test_preds_1.csv\")\n",
    "test_pred_2 = pd.read_csv(\"test_preds_2.csv\")\n",
    "test_pred_3 = pd.read_csv(\"test_preds_3.csv\")\n",
    "\n",
    "train_data = train_data.merge(train_pred_1, on=\"id\", how=\"left\")\n",
    "train_data = train_data.merge(train_pred_2, on=\"id\", how=\"left\")\n",
    "train_data = train_data.merge(train_pred_3, on=\"id\", how=\"left\")\n",
    "\n",
    "test_data = pd.concat([test_data, test_pred_1, test_pred_2, test_pred_3], join=\"inner\", axis=1)\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "test_data[\"id\"] = test_pred_1[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e462d6",
   "metadata": {
    "papermill": {
     "duration": 0.042438,
     "end_time": "2021-09-01T01:46:01.156666",
     "exception": false,
     "start_time": "2021-09-01T01:46:01.114228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting useful features/columns from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04f7672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:46:01.255169Z",
     "iopub.status.busy": "2021-09-01T01:46:01.254443Z",
     "iopub.status.idle": "2021-09-01T01:46:01.263686Z",
     "shell.execute_reply": "2021-09-01T01:46:01.264226Z",
     "shell.execute_reply.started": "2021-09-01T01:33:33.170677Z"
    },
    "papermill": {
     "duration": 0.065702,
     "end_time": "2021-09-01T01:46:01.264378",
     "exception": false,
     "start_time": "2021-09-01T01:46:01.198676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.070074</td>\n",
       "      <td>8.082083</td>\n",
       "      <td>8.110340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.362631</td>\n",
       "      <td>8.389063</td>\n",
       "      <td>8.352780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.372488</td>\n",
       "      <td>8.400261</td>\n",
       "      <td>8.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.466038</td>\n",
       "      <td>8.462927</td>\n",
       "      <td>8.441732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.137090</td>\n",
       "      <td>8.182848</td>\n",
       "      <td>8.148008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_1    pred_2    pred_3\n",
       "0  8.070074  8.082083  8.110340\n",
       "1  8.362631  8.389063  8.352780\n",
       "2  8.372488  8.400261  8.397600\n",
       "3  8.466038  8.462927  8.441732\n",
       "4  8.137090  8.182848  8.148008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_cols = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
    "test_data = test_data[useful_cols]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c24e2",
   "metadata": {
    "papermill": {
     "duration": 0.043848,
     "end_time": "2021-09-01T01:46:01.357246",
     "exception": false,
     "start_time": "2021-09-01T01:46:01.313398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final Model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train_dadta`) for training and testing\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **Linear Regression** to make the model and predict validation data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f89dc865",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:46:01.448653Z",
     "iopub.status.busy": "2021-09-01T01:46:01.447962Z",
     "iopub.status.idle": "2021-09-01T01:46:01.495493Z",
     "shell.execute_reply": "2021-09-01T01:46:01.495022Z",
     "shell.execute_reply.started": "2021-09-01T01:33:39.933372Z"
    },
    "papermill": {
     "duration": 0.095425,
     "end_time": "2021-09-01T01:46:01.495622",
     "exception": false,
     "start_time": "2021-09-01T01:46:01.400197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# K-fold splitting where total folds = 5\n",
    "train_data[\"kfold\"] = -1\n",
    "Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "    train_data.loc[valid_index, \"kfold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f6865a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:46:01.590811Z",
     "iopub.status.busy": "2021-09-01T01:46:01.589975Z",
     "iopub.status.idle": "2021-09-01T01:46:02.383027Z",
     "shell.execute_reply": "2021-09-01T01:46:02.384137Z",
     "shell.execute_reply.started": "2021-09-01T01:33:41.638564Z"
    },
    "papermill": {
     "duration": 0.845904,
     "end_time": "2021-09-01T01:46:02.384398",
     "exception": false,
     "start_time": "2021-09-01T01:46:01.538494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, RMSE: 0.7159473211978672, \n",
      "Test predictions[8.08463427 8.38272217 8.40257001 ... 8.44349284 8.11749513 7.9118475 ]\n",
      "Fold: 1, RMSE: 0.7237873644001014, \n",
      "Test predictions[8.08450619 8.38252023 8.40210127 ... 8.44308438 8.11768394 7.91229768]\n",
      "Fold: 2, RMSE: 0.7193191382604242, \n",
      "Test predictions[8.08424944 8.38462479 8.40437404 ... 8.44481154 8.11897187 7.90718247]\n",
      "Fold: 3, RMSE: 0.7188223838165171, \n",
      "Test predictions[8.08234949 8.38306543 8.40307351 ... 8.4435804  8.11668739 7.90494678]\n",
      "Fold: 4, RMSE: 0.7139512618883442, \n",
      "Test predictions[8.08355385 8.38199414 8.40270361 ... 8.44361367 8.1151673  7.90950595]\n"
     ]
    }
   ],
   "source": [
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    X_train =  train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "\n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    valid_preds = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "    print(f\"Fold: {fold}, RMSE: {rmse}, \\nTest predictions{test_preds}\")\n",
    "    scores.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425baa6b",
   "metadata": {
    "papermill": {
     "duration": 0.063516,
     "end_time": "2021-09-01T01:46:02.532526",
     "exception": false,
     "start_time": "2021-09-01T01:46:02.469010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submitting the Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc2b9ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:46:02.624774Z",
     "iopub.status.busy": "2021-09-01T01:46:02.623643Z",
     "iopub.status.idle": "2021-09-01T01:46:03.449417Z",
     "shell.execute_reply": "2021-09-01T01:46:03.448442Z",
     "shell.execute_reply.started": "2021-09-01T01:33:52.646606Z"
    },
    "papermill": {
     "duration": 0.874073,
     "end_time": "2021-09-01T01:46:03.449561",
     "exception": false,
     "start_time": "2021-09-01T01:46:02.575488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 595.594031,
   "end_time": "2021-09-01T01:46:04.202134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-01T01:36:08.608103",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
