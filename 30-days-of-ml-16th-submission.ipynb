{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94879cf7",
   "metadata": {
    "papermill": {
     "duration": 0.015824,
     "end_time": "2021-09-01T01:53:56.973410",
     "exception": false,
     "start_time": "2021-09-01T01:53:56.957586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50d97e7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-01T01:53:57.017308Z",
     "iopub.status.busy": "2021-09-01T01:53:57.016629Z",
     "iopub.status.idle": "2021-09-01T01:53:58.718493Z",
     "shell.execute_reply": "2021-09-01T01:53:58.717353Z",
     "shell.execute_reply.started": "2021-09-01T01:35:53.111055Z"
    },
    "papermill": {
     "duration": 1.729506,
     "end_time": "2021-09-01T01:53:58.718674",
     "exception": false,
     "start_time": "2021-09-01T01:53:56.989168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054c1cb",
   "metadata": {
    "papermill": {
     "duration": 0.016143,
     "end_time": "2021-09-01T01:53:58.749875",
     "exception": false,
     "start_time": "2021-09-01T01:53:58.733732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1st model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train.csv`) for training and testing where folds = 5\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **Ordinal Encoding** on optuna_model_1 to get numerical values of categorical values\n",
    "##### **One Hot Encoding** on model_1 to get numerical values of categorical values\n",
    "##### **XGBoost** to make the model and predict validation data and test data n estimators=1000\n",
    "____________________________________________________________________________________________________\n",
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57cbe7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:53:58.814894Z",
     "iopub.status.busy": "2021-09-01T01:53:58.813094Z",
     "iopub.status.idle": "2021-09-01T01:53:58.815494Z",
     "shell.execute_reply": "2021-09-01T01:53:58.815925Z",
     "shell.execute_reply.started": "2021-09-01T00:43:08.713007Z"
    },
    "papermill": {
     "duration": 0.051491,
     "end_time": "2021-09-01T01:53:58.816074",
     "exception": false,
     "start_time": "2021-09-01T01:53:58.764583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1st model\n",
    "def model_1():\n",
    "    train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "    test_preds_1 = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "    \n",
    "    # K-fold splitting where total folds = 5\n",
    "    train_data[\"kfold\"] = -1\n",
    "    Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "    for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "        train_data.loc[valid_index, \"kfold\"] = fold\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required models\n",
    "    num_cols = [col for col in train_data.columns if \"cont\" in col]\n",
    "    cat_cols = [col for col in train_data.columns if \"cat\" in col]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    model_1_train_data = train_data\n",
    "    model_1_test_data = test_data\n",
    "    test_data = test_data[useful_cols]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Target Encoding\n",
    "    # Iterate over categorical columns\n",
    "    for col in cat_cols:\n",
    "        \"\"\"\n",
    "        Based on each categorical column, one target fold is created\n",
    "        total 5 folds for one column\n",
    "        \"\"\"\n",
    "        temp_train = []\n",
    "        temp_test_target = None\n",
    "        for fold in range(5):\n",
    "            # making training data and validating data for each fold\n",
    "            X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "            X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "            \n",
    "            # getting the mean of training data target\n",
    "            mean_target = dict(X_train.groupby(col)[\"target\"].agg(\"median\"))\n",
    "\n",
    "            # adding the mean_target to X_valid (valid dataset of each fold)\n",
    "            X_valid.loc[:, f\"target_enc_{col}\"] = X_valid[col].map(mean_target)\n",
    "            temp_train.append(X_valid)\n",
    "            if (temp_test_target is None):\n",
    "                temp_test_target = test_data[col].map(mean_target)\n",
    "            else:\n",
    "                temp_test_target += test_data[col].map(mean_target)\n",
    "                \n",
    "        # getting the average of temporary test target on each column\n",
    "        temp_test_target /= 5\n",
    "        # adding the temporary test target to test data on each column (total=5)\n",
    "        test_data.loc[:, f\"target_enc_{col}\"] = temp_test_target\n",
    "\n",
    "        # setting training data as temp_train\n",
    "        train_data = pd.concat(temp_train)\n",
    "        \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required columns again\n",
    "    useful_cols = [col for col in train_data.columns if ((train_data[col].dtypes == \"int64\") or (train_data[col].dtypes ==\"float64\")) and (col not in (\"id\"))]\n",
    "    cat_cols = [col for col in train_data.columns if (train_data[col].dtypes == \"object\")]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    train_data = train_data[useful_cols]\n",
    "    test_data = test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # optuna model 1 for final model 1\n",
    "    def optuna_model_1(trial):\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # Setting required columns again\n",
    "        useful_cols = [col for col in model_1_train_data.columns if ((model_1_train_data[col].dtypes == \"int64\") or (model_1_train_data[col].dtypes ==\"float64\")) and (col != \"id\")]\n",
    "        cat_cols = [col for col in model_1_test_data.columns if (model_1_test_data[col].dtypes == \"object\")]\n",
    "        useful_cols = cat_cols + num_cols\n",
    "        train_data = model_1_train_data[useful_cols]\n",
    "        test_data = model_1_test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # making parameteres\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.5, log=True)\n",
    "        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        \n",
    "        fold = 0\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_1_train_data[model_1_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_1_train_data[model_1_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        # setting the target\n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        # setting the training data and validating data\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "\n",
    "        # making model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=2000,\n",
    "            learning_rate=learning_rate,\n",
    "            reg_lambda=reg_lambda,\n",
    "            reg_alpha=reg_alpha,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            max_depth=max_depth,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=50,\n",
    "        )\n",
    "        # fitting data into the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=300,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=1000)\n",
    "\n",
    "        # getting predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        # getting RMSE\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        return rmse\n",
    "    #==============================================================================================================================================================================#\n",
    "    # Optimizing optuna_model and getting best parameters\n",
    "    optuna_1 = optuna.create_study(direction=\"minimize\")\n",
    "    optuna_1.optimize(optuna_model_1, n_trials=5)\n",
    "    best_params_model_1 = optuna_1.best_params\n",
    "    #==============================================================================================================================================================================#\n",
    "    # final_model made by XGB Regressor\n",
    "    final_valid_predictions = {}\n",
    "    final_test_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_1_train_data[model_1_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_1_train_data[model_1_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        X_test = test_data.copy()\n",
    "\n",
    "        valid_ids = X_valid.id.values.tolist()\n",
    "        \n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## One Hot Encoding for categorical data\n",
    "        OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        OH_encoder.fit(X_train[cat_cols])\n",
    "        OH_X_train = OH_encoder.transform(X_train[cat_cols])\n",
    "        OH_X_valid = OH_encoder.transform(X_valid[cat_cols])\n",
    "        OH_X_test = OH_encoder.transform(X_test[cat_cols])\n",
    "\n",
    "        # Naming the one hot encoded columns\n",
    "        OH_X_train = pd.DataFrame(OH_X_train, columns=[f\"ohe_{i}\" for i in range(OH_X_train.shape[1])])\n",
    "        OH_X_valid = pd.DataFrame(OH_X_valid, columns=[f\"ohe_{i}\" for i in range(OH_X_valid.shape[1])])\n",
    "        OH_X_test = pd.DataFrame(OH_X_test, columns=[f\"ohe_{i}\" for i in range(OH_X_test.shape[1])])\n",
    "\n",
    "        # Adding one hot encoded columns to main data (training, validating, test)\n",
    "        X_train = pd.concat([X_train, OH_X_train], axis=1)\n",
    "        X_valid = pd.concat([X_valid, OH_X_valid], axis=1)\n",
    "        X_test = pd.concat([X_test, OH_X_test], axis=1)\n",
    "\n",
    "        # Dropping the categorical columns, as their one hot encoded columns are added to main data\n",
    "        X_train = X_train.drop(cat_cols, axis=1)\n",
    "        X_valid = X_valid.drop(cat_cols, axis=1)\n",
    "        X_test = X_test.drop(cat_cols, axis=1)\n",
    "\n",
    "        # making the model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=2000,\n",
    "            **best_params_model_1,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=50,\n",
    "        )\n",
    "        # fitting the data in the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=300,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=1000)\n",
    "\n",
    "        # getting valid predictions and test predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "        test_preds = model.predict(X_test)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n",
    "        final_test_predictions.append(test_preds)\n",
    "\n",
    "        # rmse on valid predictions\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    valid_preds_1 = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    valid_preds_1.columns = [\"id\", \"pred_1\"]\n",
    "    valid_preds_1.to_csv(\"train_preds_1.csv\", index=False)\n",
    "    \n",
    "    test_preds_1.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    test_preds_1.columns = [\"id\", \"pred_1\"]\n",
    "    test_preds_1.to_csv(\"test_preds_1.csv\", index=False)\n",
    "    return scores, test_preds_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323b030",
   "metadata": {
    "papermill": {
     "duration": 0.014323,
     "end_time": "2021-09-01T01:53:58.845426",
     "exception": false,
     "start_time": "2021-09-01T01:53:58.831103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE and Test Predictions on model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27812b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:53:58.880352Z",
     "iopub.status.busy": "2021-09-01T01:53:58.879802Z",
     "iopub.status.idle": "2021-09-01T01:55:31.169278Z",
     "shell.execute_reply": "2021-09-01T01:55:31.169749Z",
     "shell.execute_reply.started": "2021-09-01T00:43:09.170345Z"
    },
    "papermill": {
     "duration": 92.308856,
     "end_time": "2021-09-01T01:55:31.169918",
     "exception": false,
     "start_time": "2021-09-01T01:53:58.861062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:54:09,667]\u001b[0m A new study created in memory with name: no-name-8c7d9bec-b94b-404e-b0d7-522b6508ff1a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.14876\n",
      "[1000]\tvalidation_0-rmse:0.71694\n",
      "[1528]\tvalidation_0-rmse:0.71708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:54:17,273]\u001b[0m Trial 0 finished with value: 0.7168378950538234 and parameters: {'learning_rate': 0.08133944387862009, 'reg_lambda': 91.96725706667004, 'reg_alpha': 9.137793303669227e-08, 'subsample': 0.6990687555707329, 'colsample_bytree': 0.5686016109955158, 'max_depth': 4}. Best is trial 0 with value: 0.7168378950538234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6.76476\n",
      "[444]\tvalidation_0-rmse:0.72559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:54:22,168]\u001b[0m Trial 1 finished with value: 0.7220245838974617 and parameters: {'learning_rate': 0.13119332427712838, 'reg_lambda': 0.14169864669904933, 'reg_alpha': 1.4712023503641833e-06, 'subsample': 0.29869237594397197, 'colsample_bytree': 0.2769129760715793, 'max_depth': 6}. Best is trial 0 with value: 0.7168378950538234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6.50524\n",
      "[401]\tvalidation_0-rmse:0.73011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:54:26,726]\u001b[0m Trial 2 finished with value: 0.7233763044455628 and parameters: {'learning_rate': 0.16487509719268212, 'reg_lambda': 0.0005619946547244303, 'reg_alpha': 0.0459393619370181, 'subsample': 0.3790941303657904, 'colsample_bytree': 0.5824886507986692, 'max_depth': 6}. Best is trial 0 with value: 0.7168378950538234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6.81722\n",
      "[679]\tvalidation_0-rmse:0.71936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:54:32,942]\u001b[0m Trial 3 finished with value: 0.7177978383792132 and parameters: {'learning_rate': 0.12434298582395381, 'reg_lambda': 1.2632361311719154, 'reg_alpha': 1.37836852882006e-05, 'subsample': 0.6870507957204991, 'colsample_bytree': 0.18695451114722828, 'max_depth': 6}. Best is trial 0 with value: 0.7168378950538234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:5.51380\n",
      "[426]\tvalidation_0-rmse:0.72373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:54:37,114]\u001b[0m Trial 4 finished with value: 0.7199435099151316 and parameters: {'learning_rate': 0.29391906110343075, 'reg_lambda': 0.8863725041351904, 'reg_alpha': 3.7245295352231127e-07, 'subsample': 0.9666774776812908, 'colsample_bytree': 0.43004202164162153, 'max_depth': 5}. Best is trial 0 with value: 0.7168378950538234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.14876\n",
      "[1000]\tvalidation_0-rmse:0.71709\n",
      "[1530]\tvalidation_0-rmse:0.71713\n",
      "[0]\tvalidation_0-rmse:7.15224\n",
      "[1000]\tvalidation_0-rmse:0.72464\n",
      "[1552]\tvalidation_0-rmse:0.72468\n",
      "[0]\tvalidation_0-rmse:7.14819\n",
      "[1000]\tvalidation_0-rmse:0.72021\n",
      "[1618]\tvalidation_0-rmse:0.72018\n",
      "[0]\tvalidation_0-rmse:7.15468\n",
      "[1000]\tvalidation_0-rmse:0.71980\n",
      "[1593]\tvalidation_0-rmse:0.71989\n",
      "[0]\tvalidation_0-rmse:7.15438\n",
      "[1000]\tvalidation_0-rmse:0.71473\n",
      "[1565]\tvalidation_0-rmse:0.71460\n",
      "MSE: [0.7169609374018332, 0.7244526982367475, 0.7199796820374822, 0.7197370484788822, 0.7144074191873216]\n",
      "Test data predictions:             id    pred_1\n",
      "0            0  8.090875\n",
      "1            5  8.369916\n",
      "2           15  8.402437\n",
      "3           16  8.499657\n",
      "4           17  8.180559\n",
      "...        ...       ...\n",
      "199995  499987  8.103170\n",
      "199996  499990  8.423574\n",
      "199997  499991  8.470532\n",
      "199998  499994  8.113050\n",
      "199999  499995  7.908584\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model_1 MSE and test_predictions\n",
    "mse_1, final_preds_1 = model_1()\n",
    "print(f\"MSE: {mse_1}\\nTest data predictions: {final_preds_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528f4ba",
   "metadata": {
    "papermill": {
     "duration": 0.022459,
     "end_time": "2021-09-01T01:55:31.215196",
     "exception": false,
     "start_time": "2021-09-01T01:55:31.192737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2nd model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train.csv`) for training and testing where folds = 5\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **One Hot Encoding** on optuna_model_1 to get numerical values of categorical values\n",
    "##### **Ordinal Encoding** on model_1 to get numerical values of categorical values\n",
    "##### **XGB Regressor** to make the model and predict validation data and test data n estimators=5000\n",
    "____________________________________________________________________________________________________\n",
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4ce0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:55:31.294643Z",
     "iopub.status.busy": "2021-09-01T01:55:31.286186Z",
     "iopub.status.idle": "2021-09-01T01:55:31.297209Z",
     "shell.execute_reply": "2021-09-01T01:55:31.296725Z",
     "shell.execute_reply.started": "2021-09-01T00:44:59.164158Z"
    },
    "papermill": {
     "duration": 0.058107,
     "end_time": "2021-09-01T01:55:31.297328",
     "exception": false,
     "start_time": "2021-09-01T01:55:31.239221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2nd model\n",
    "def model_2():\n",
    "    train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "    test_preds_2 = sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "    \n",
    "    # K-fold splitting where total folds = 5\n",
    "    train_data[\"kfold\"] = -1\n",
    "    Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "    for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "        train_data.loc[valid_index, \"kfold\"] = fold\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required models\n",
    "    num_cols = [col for col in train_data.columns if \"cont\" in col]\n",
    "    cat_cols = [col for col in train_data.columns if \"cat\" in col]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    model_2_train_data = train_data\n",
    "    model_2_test_data = test_data\n",
    "    test_data = test_data[useful_cols]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Target Encoding\n",
    "    # Iterate over categorical columns\n",
    "    for col in cat_cols:\n",
    "        \"\"\"\n",
    "        Based on each categorical column, one target fold is created\n",
    "        total 5 folds for one column\n",
    "        \"\"\"\n",
    "        temp_train = []\n",
    "        temp_test_target = None\n",
    "        for fold in range(5):\n",
    "            # making training data and validating data for each fold\n",
    "            X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "            X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "            \n",
    "            # getting the mean of training data target\n",
    "            mean_target = dict(X_train.groupby(col)[\"target\"].agg(\"median\"))\n",
    "\n",
    "            # adding the mean_target to X_valid (valid dataset of each fold)\n",
    "            X_valid.loc[:, f\"target_enc_{col}\"] = X_valid[col].map(mean_target)\n",
    "            temp_train.append(X_valid)\n",
    "            if (temp_test_target is None):\n",
    "                temp_test_target = test_data[col].map(mean_target)\n",
    "            else:\n",
    "                temp_test_target += test_data[col].map(mean_target)\n",
    "                \n",
    "        # getting the average of temporary test target on each column\n",
    "        temp_test_target /= 5\n",
    "        # adding the temporary test target to test data on each column (total=5)\n",
    "        test_data.loc[:, f\"target_enc_{col}\"] = temp_test_target\n",
    "\n",
    "        # setting training data as temp_train\n",
    "        train_data = pd.concat(temp_train)\n",
    "        \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required columns again\n",
    "    useful_cols = [col for col in train_data.columns if ((train_data[col].dtypes == \"int64\") or (train_data[col].dtypes ==\"float64\")) and (col not in (\"id\"))]\n",
    "    cat_cols = [col for col in train_data.columns if (train_data[col].dtypes == \"object\")]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    train_data = train_data[useful_cols]\n",
    "    test_data = test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # optuna model 2 for final model 2\n",
    "    def optuna_model_2(trial):\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # Setting required columns again\n",
    "        useful_cols = [col for col in model_2_train_data.columns if ((model_2_train_data[col].dtypes == \"int64\") or (model_2_train_data[col].dtypes ==\"float64\")) and (col != \"id\")]\n",
    "        cat_cols = [col for col in model_2_test_data.columns if (model_2_test_data[col].dtypes == \"object\")]\n",
    "        useful_cols = cat_cols + num_cols\n",
    "        train_data = model_2_train_data[useful_cols]\n",
    "        test_data = model_2_test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # making parameteres\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.05, log=True)\n",
    "        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        \n",
    "        fold = 0\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_2_train_data[model_2_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_2_train_data[model_2_train_data.kfold == fold].reset_index(drop=True)\n",
    "        \n",
    "        X_test = test_data.copy()\n",
    "        \n",
    "        # setting the target\n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        # setting the training data and validating data\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## One Hot Encoding for categorical data\n",
    "        OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        OH_encoder.fit(X_train[cat_cols])\n",
    "        OH_X_train = OH_encoder.transform(X_train[cat_cols])\n",
    "        OH_X_valid = OH_encoder.transform(X_valid[cat_cols])\n",
    "\n",
    "        # Naming the one hot encoded columns\n",
    "        OH_X_train = pd.DataFrame(OH_X_train, columns=[f\"ohe_{i}\" for i in range(OH_X_train.shape[1])])\n",
    "        OH_X_valid = pd.DataFrame(OH_X_valid, columns=[f\"ohe_{i}\" for i in range(OH_X_valid.shape[1])])\n",
    "\n",
    "        # Adding one hot encoded columns to main data (training, validating, test)\n",
    "        X_train = pd.concat([X_train, OH_X_train], axis=1)\n",
    "        X_valid = pd.concat([X_valid, OH_X_valid], axis=1)\n",
    "\n",
    "        # Dropping the categorical columns, as their one hot encoded columns are added to main data\n",
    "        X_train = X_train.drop(cat_cols, axis=1)\n",
    "        X_valid = X_valid.drop(cat_cols, axis=1)\n",
    "\n",
    "        # making model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=5000,\n",
    "            learning_rate=learning_rate,\n",
    "            reg_lambda=reg_lambda,\n",
    "            reg_alpha=reg_alpha,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            max_depth=max_depth,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting data into the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=500,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=2000)\n",
    "\n",
    "        # getting predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        # getting RMSE\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        return rmse\n",
    "    #==============================================================================================================================================================================#\n",
    "    # Optimizing optuna_model and getting best parameters\n",
    "    optuna_2 = optuna.create_study(direction=\"minimize\")\n",
    "    optuna_2.optimize(optuna_model_2, n_trials=5)\n",
    "    best_params_model_2 = optuna_2.best_params\n",
    "    #==============================================================================================================================================================================#\n",
    "    # final_model made by XGB Regressor\n",
    "    final_valid_predictions = {}\n",
    "    final_test_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_2_train_data[model_2_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_2_train_data[model_2_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        X_test = test_data.copy()\n",
    "\n",
    "        valid_ids = X_valid.id.values.tolist()\n",
    "        \n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "        \n",
    "        ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "        X_test[cat_cols] = Ord_encoder.transform(X_test[cat_cols])\n",
    "\n",
    "        # making the model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=5000,\n",
    "            **best_params_model_2,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting the data in the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=500,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=2000)\n",
    "\n",
    "        # getting valid predictions and test predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "        test_preds = model.predict(X_test)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n",
    "        final_test_predictions.append(test_preds)\n",
    "\n",
    "        # rmse on valid predictions\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    valid_preds_2 = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    valid_preds_2.columns = [\"id\", \"pred_2\"]\n",
    "    valid_preds_2.to_csv(\"train_preds_2.csv\", index=False)\n",
    "    \n",
    "    test_preds_2.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    test_preds_2.columns = [\"id\", \"pred_2\"]\n",
    "    test_preds_2.to_csv(\"test_preds_2.csv\", index=False)\n",
    "    return scores, test_preds_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c5175",
   "metadata": {
    "papermill": {
     "duration": 0.022873,
     "end_time": "2021-09-01T01:55:31.343116",
     "exception": false,
     "start_time": "2021-09-01T01:55:31.320243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE and Test Predictions on model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a40ad0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:55:31.393048Z",
     "iopub.status.busy": "2021-09-01T01:55:31.392509Z",
     "iopub.status.idle": "2021-09-01T01:59:37.436203Z",
     "shell.execute_reply": "2021-09-01T01:59:37.436801Z",
     "shell.execute_reply.started": "2021-09-01T00:44:59.197753Z"
    },
    "papermill": {
     "duration": 246.070784,
     "end_time": "2021-09-01T01:59:37.437026",
     "exception": false,
     "start_time": "2021-09-01T01:55:31.366242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:55:40,661]\u001b[0m A new study created in memory with name: no-name-220fd072-4dea-4750-86eb-714479cfe057\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.65826\n",
      "[2000]\tvalidation_0-rmse:0.72013\n",
      "[2151]\tvalidation_0-rmse:0.72023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:56:09,035]\u001b[0m Trial 0 finished with value: 0.7199314404999175 and parameters: {'learning_rate': 0.015173066720321393, 'reg_lambda': 0.08454325416428177, 'reg_alpha': 3.249016813790478e-08, 'subsample': 0.2897787354798519, 'colsample_bytree': 0.9842939095643247, 'max_depth': 7}. Best is trial 0 with value: 0.7199314404999175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.59976\n",
      "[1033]\tvalidation_0-rmse:0.72430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:56:34,721]\u001b[0m Trial 1 finished with value: 0.7229272220579959 and parameters: {'learning_rate': 0.022753860330639808, 'reg_lambda': 6.589764870652293e-08, 'reg_alpha': 6.248059142746158e-05, 'subsample': 0.10668869447273817, 'colsample_bytree': 0.22833640595679433, 'max_depth': 9}. Best is trial 0 with value: 0.7199314404999175.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.63957\n",
      "[2000]\tvalidation_0-rmse:0.72505\n",
      "[4000]\tvalidation_0-rmse:0.72104\n",
      "[4999]\tvalidation_0-rmse:0.71988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:56:52,705]\u001b[0m Trial 2 finished with value: 0.719878015740238 and parameters: {'learning_rate': 0.01759525685674353, 'reg_lambda': 0.3490040805860492, 'reg_alpha': 0.022701877538455064, 'subsample': 0.8055536799979458, 'colsample_bytree': 0.6573107702778506, 'max_depth': 2}. Best is trial 2 with value: 0.719878015740238.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.52992\n",
      "[1071]\tvalidation_0-rmse:0.72084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:57:28,933]\u001b[0m Trial 3 finished with value: 0.7196248224818687 and parameters: {'learning_rate': 0.03182949044196197, 'reg_lambda': 1.9109285658982982e-05, 'reg_alpha': 3.991316425829756, 'subsample': 0.6729636731518039, 'colsample_bytree': 0.8513150675199644, 'max_depth': 9}. Best is trial 3 with value: 0.7196248224818687.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.65918\n",
      "[2000]\tvalidation_0-rmse:0.71862\n",
      "[4000]\tvalidation_0-rmse:0.71780\n",
      "[4759]\tvalidation_0-rmse:0.71784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:57:56,712]\u001b[0m Trial 4 finished with value: 0.71777300602988 and parameters: {'learning_rate': 0.015053867176857803, 'reg_lambda': 2.255514823127675e-07, 'reg_alpha': 0.003093819699313589, 'subsample': 0.33014474729008103, 'colsample_bytree': 0.5850581273919265, 'max_depth': 5}. Best is trial 4 with value: 0.71777300602988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.65918\n",
      "[2000]\tvalidation_0-rmse:0.71871\n",
      "[4000]\tvalidation_0-rmse:0.71789\n",
      "[4149]\tvalidation_0-rmse:0.71795\n",
      "[0]\tvalidation_0-rmse:7.66237\n",
      "[2000]\tvalidation_0-rmse:0.72641\n",
      "[4000]\tvalidation_0-rmse:0.72560\n",
      "[4258]\tvalidation_0-rmse:0.72560\n",
      "[0]\tvalidation_0-rmse:7.65842\n",
      "[2000]\tvalidation_0-rmse:0.72227\n",
      "[4000]\tvalidation_0-rmse:0.72110\n",
      "[4673]\tvalidation_0-rmse:0.72103\n",
      "[0]\tvalidation_0-rmse:7.66486\n",
      "[2000]\tvalidation_0-rmse:0.72114\n",
      "[3855]\tvalidation_0-rmse:0.72040\n",
      "[0]\tvalidation_0-rmse:7.66459\n",
      "[2000]\tvalidation_0-rmse:0.71684\n",
      "[4000]\tvalidation_0-rmse:0.71550\n",
      "[4571]\tvalidation_0-rmse:0.71550\n",
      "MSE: [0.7178632073212032, 0.7255448064223806, 0.7209973852429764, 0.7203936121150996, 0.7154673262846395]\n",
      "Test data predictions:             id    pred_2\n",
      "0            0  8.079402\n",
      "1            5  8.367846\n",
      "2           15  8.383591\n",
      "3           16  8.440797\n",
      "4           17  8.179073\n",
      "...        ...       ...\n",
      "199995  499987  8.132765\n",
      "199996  499990  8.401813\n",
      "199997  499991  8.442299\n",
      "199998  499994  8.107409\n",
      "199999  499995  7.911824\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model_2 MSE and test_predictions\n",
    "mse_2, final_preds_2 = model_2()\n",
    "print(f\"MSE: {mse_2}\\nTest data predictions: {final_preds_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509161dd",
   "metadata": {
    "papermill": {
     "duration": 0.033973,
     "end_time": "2021-09-01T01:59:37.507600",
     "exception": false,
     "start_time": "2021-09-01T01:59:37.473627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3rd model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train.csv`) for training and testing where folds = 5\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **One Hot Encoding** on optuna_model_1 to get numerical values of categorical values\n",
    "##### **Ordinal Encoding** on model_1 to get numerical values of categorical values\n",
    "##### **XGB Regressor** to make the model and predict validation data and test data n estimators=10000\n",
    "____________________________________________________________________________________________________\n",
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6edfc5ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:59:37.606389Z",
     "iopub.status.busy": "2021-09-01T01:59:37.602523Z",
     "iopub.status.idle": "2021-09-01T01:59:37.608920Z",
     "shell.execute_reply": "2021-09-01T01:59:37.608495Z",
     "shell.execute_reply.started": "2021-09-01T00:51:56.647519Z"
    },
    "papermill": {
     "duration": 0.066844,
     "end_time": "2021-09-01T01:59:37.609041",
     "exception": false,
     "start_time": "2021-09-01T01:59:37.542197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3rd model\n",
    "def model_3():\n",
    "    train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "    test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "    test_preds_3 = sample_submission_3 = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "    \n",
    "    # K-fold splitting where total folds = 5\n",
    "    train_data[\"kfold\"] = -1\n",
    "    Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "    for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "        train_data.loc[valid_index, \"kfold\"] = fold\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required models\n",
    "    num_cols = [col for col in train_data.columns if \"cont\" in col]\n",
    "    cat_cols = [col for col in train_data.columns if \"cat\" in col]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    model_3_train_data = train_data\n",
    "    model_3_test_data = test_data\n",
    "    test_data = test_data[useful_cols]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Target Encoding\n",
    "    # Iterate over categorical columns\n",
    "    for col in cat_cols:\n",
    "        \"\"\"\n",
    "        Based on each categorical column, one target fold is created\n",
    "        total 5 folds for one column\n",
    "        \"\"\"\n",
    "        temp_train = []\n",
    "        temp_test_target = None\n",
    "        for fold in range(5):\n",
    "            # making training data and validating data for each fold\n",
    "            X_train = train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "            X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "            \n",
    "            # getting the mean of training data target\n",
    "            mean_target = dict(X_train.groupby(col)[\"target\"].agg(\"median\"))\n",
    "\n",
    "            # adding the mean_target to X_valid (valid dataset of each fold)\n",
    "            X_valid.loc[:, f\"target_enc_{col}\"] = X_valid[col].map(mean_target)\n",
    "            temp_train.append(X_valid)\n",
    "            if (temp_test_target is None):\n",
    "                temp_test_target = test_data[col].map(mean_target)\n",
    "            else:\n",
    "                temp_test_target += test_data[col].map(mean_target)\n",
    "                \n",
    "        # getting the average of temporary test target on each column\n",
    "        temp_test_target /= 5\n",
    "        # adding the temporary test target to test data on each column (total=5)\n",
    "        test_data.loc[:, f\"target_enc_{col}\"] = temp_test_target\n",
    "\n",
    "        # setting training data as temp_train\n",
    "        train_data = pd.concat(temp_train)\n",
    "        \n",
    "    #==============================================================================================================================================================================#\n",
    "    # Setting required columns again\n",
    "    useful_cols = [col for col in train_data.columns if ((train_data[col].dtypes == \"int64\") or (train_data[col].dtypes ==\"float64\")) and (col not in (\"id\"))]\n",
    "    cat_cols = [col for col in train_data.columns if (train_data[col].dtypes == \"object\")]\n",
    "    useful_cols = cat_cols + num_cols\n",
    "    train_data = train_data[useful_cols]\n",
    "    test_data = test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    # optuna model 3 for final model 3\n",
    "    def optuna_model_3(trial):\n",
    "        \n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # Setting required columns again\n",
    "        useful_cols = [col for col in model_3_train_data.columns if ((model_3_train_data[col].dtypes == \"int64\") or (model_3_train_data[col].dtypes ==\"float64\")) and (col != \"id\")]\n",
    "        cat_cols = [col for col in model_3_test_data.columns if (model_3_test_data[col].dtypes == \"object\")]\n",
    "        useful_cols = cat_cols + num_cols\n",
    "        train_data = model_3_train_data[useful_cols]\n",
    "        test_data = model_3_test_data[useful_cols[:24] + useful_cols[26:]]\n",
    "\n",
    "        #---------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "        # making parameteres\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.5, log=True)\n",
    "        reg_lambda = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
    "        reg_alpha = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "        \n",
    "        fold = 0\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_3_train_data[model_3_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_3_train_data[model_3_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        # setting the target\n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        # setting the training data and validating data\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "        ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "\n",
    "        # making model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=10000,\n",
    "            learning_rate=learning_rate,\n",
    "            reg_lambda=reg_lambda,\n",
    "            reg_alpha=reg_alpha,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            max_depth=max_depth,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting data into the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=1000,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=5000)\n",
    "\n",
    "        # getting predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "\n",
    "        # getting RMSE\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        return rmse\n",
    "    #==============================================================================================================================================================================#\n",
    "    \n",
    "    # Optimizing optuna_model and getting best parameters\n",
    "    optuna_3 = optuna.create_study(direction=\"minimize\")\n",
    "    optuna_3.optimize(optuna_model_3, n_trials=5)\n",
    "    best_params_model_3 = optuna_3.best_params\n",
    "    #==============================================================================================================================================================================#\n",
    "    \n",
    "    # final_model made by XGB Regressor\n",
    "    final_valid_predictions = {}\n",
    "    final_test_predictions = []\n",
    "    scores = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        # making training data and validating data for each fold\n",
    "        X_train = model_3_train_data[model_3_train_data.kfold != fold].reset_index(drop=True)\n",
    "        X_valid = model_3_train_data[model_3_train_data.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        X_test = test_data.copy()\n",
    "\n",
    "        valid_ids = X_valid.id.values.tolist()\n",
    "        \n",
    "        y_train = X_train.target\n",
    "        y_valid = X_valid.target\n",
    "\n",
    "        X_train = X_train[test_data.columns]\n",
    "        X_valid = X_valid[test_data.columns]\n",
    "\n",
    "         ## Ordinal for categorical data\n",
    "        Ord_encoder = OrdinalEncoder()\n",
    "\n",
    "        # fitting and transforming the training and test data\n",
    "        Ord_encoder.fit(X_train[cat_cols])\n",
    "        X_train[cat_cols] = Ord_encoder.transform(X_train[cat_cols])\n",
    "        X_valid[cat_cols] = Ord_encoder.transform(X_valid[cat_cols])\n",
    "        X_test[cat_cols] = Ord_encoder.transform(X_test[cat_cols])\n",
    "\n",
    "        # making the model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=10000,\n",
    "            **best_params_model_3,\n",
    "            tree_method=\"gpu_hist\",\n",
    "            gpu_id=0,\n",
    "            predictor=\"gpu_predictor\",\n",
    "            random_state=100,\n",
    "        )\n",
    "        # fitting the data in the model\n",
    "        model.fit(X_train, y_train, early_stopping_rounds=1000,\n",
    "                  eval_set=[(X_valid, y_valid)], verbose=5000)\n",
    "\n",
    "        # getting valid predictions and test predictions\n",
    "        valid_preds = model.predict(X_valid)\n",
    "        test_preds = model.predict(X_test)\n",
    "        final_valid_predictions.update(dict(zip(valid_ids, valid_preds)))\n",
    "        final_test_predictions.append(test_preds)\n",
    "\n",
    "        # rmse on valid predictions\n",
    "        rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    #==============================================================================================================================================================================#\n",
    "    valid_preds_3 = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "    valid_preds_3.columns = [\"id\", \"pred_3\"]\n",
    "    valid_preds_3.to_csv(\"train_preds_3.csv\", index=False)\n",
    "    \n",
    "    test_preds_3.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "    test_preds_3.columns = [\"id\", \"pred_3\"]\n",
    "    test_preds_3.to_csv(\"test_preds_3.csv\", index=False)\n",
    "    return scores, test_preds_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e6a76",
   "metadata": {
    "papermill": {
     "duration": 0.034999,
     "end_time": "2021-09-01T01:59:37.687785",
     "exception": false,
     "start_time": "2021-09-01T01:59:37.652786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MSE and Test Predictions on model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086798f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T01:59:37.763980Z",
     "iopub.status.busy": "2021-09-01T01:59:37.763312Z",
     "iopub.status.idle": "2021-09-01T02:04:37.377134Z",
     "shell.execute_reply": "2021-09-01T02:04:37.377751Z",
     "shell.execute_reply.started": "2021-09-01T00:51:56.679194Z"
    },
    "papermill": {
     "duration": 299.653869,
     "end_time": "2021-09-01T02:04:37.377964",
     "exception": false,
     "start_time": "2021-09-01T01:59:37.724095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 01:59:46,311]\u001b[0m A new study created in memory with name: no-name-4500c508-b8fa-49c9-ac76-1a8381fa4161\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.54340\n",
      "[1872]\tvalidation_0-rmse:0.71864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 02:00:34,031]\u001b[0m Trial 0 finished with value: 0.7167820921125675 and parameters: {'learning_rate': 0.030080370238632186, 'reg_lambda': 2.886592511768368, 'reg_alpha': 8.737119208333445, 'subsample': 0.5131082925009189, 'colsample_bytree': 0.2064826486494481, 'max_depth': 10}. Best is trial 0 with value: 0.7167820921125675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:6.97251\n",
      "[1048]\tvalidation_0-rmse:0.84534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 02:01:20,603]\u001b[0m Trial 1 finished with value: 0.7397773831443202 and parameters: {'learning_rate': 0.10421488593502182, 'reg_lambda': 1.4699421094873095e-08, 'reg_alpha': 0.0011492671090863576, 'subsample': 0.17233686845516344, 'colsample_bytree': 0.9639028272592877, 'max_depth': 10}. Best is trial 0 with value: 0.7167820921125675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.56422\n",
      "[5000]\tvalidation_0-rmse:0.71778\n",
      "[9999]\tvalidation_0-rmse:0.71637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 02:01:43,160]\u001b[0m Trial 2 finished with value: 0.716370745656987 and parameters: {'learning_rate': 0.02737521297057318, 'reg_lambda': 4.889331552327708e-06, 'reg_alpha': 3.4319611252803963e-07, 'subsample': 0.6776601857441027, 'colsample_bytree': 0.9714058621268021, 'max_depth': 2}. Best is trial 2 with value: 0.716370745656987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:5.62003\n",
      "[1022]\tvalidation_0-rmse:1.02959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 02:01:59,745]\u001b[0m Trial 3 finished with value: 0.7437111505616736 and parameters: {'learning_rate': 0.28023637353468944, 'reg_lambda': 0.0012009972875386228, 'reg_alpha': 0.005599371211538415, 'subsample': 0.11793435721863486, 'colsample_bytree': 0.10170424835876453, 'max_depth': 9}. Best is trial 2 with value: 0.716370745656987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.68024\n",
      "[3632]\tvalidation_0-rmse:0.71859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-01 02:02:34,491]\u001b[0m Trial 4 finished with value: 0.7183112721565323 and parameters: {'learning_rate': 0.01231768046871694, 'reg_lambda': 0.3591646374199854, 'reg_alpha': 1.1923275257125785, 'subsample': 0.6221668819112247, 'colsample_bytree': 0.8776710186958979, 'max_depth': 7}. Best is trial 2 with value: 0.716370745656987.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.56422\n",
      "[5000]\tvalidation_0-rmse:0.71778\n",
      "[9999]\tvalidation_0-rmse:0.71637\n",
      "[0]\tvalidation_0-rmse:7.56744\n",
      "[5000]\tvalidation_0-rmse:0.72522\n",
      "[9999]\tvalidation_0-rmse:0.72377\n",
      "[0]\tvalidation_0-rmse:7.56352\n",
      "[5000]\tvalidation_0-rmse:0.72119\n",
      "[9999]\tvalidation_0-rmse:0.71961\n",
      "[0]\tvalidation_0-rmse:7.56990\n",
      "[5000]\tvalidation_0-rmse:0.72047\n",
      "[9999]\tvalidation_0-rmse:0.71930\n",
      "[0]\tvalidation_0-rmse:7.56971\n",
      "[5000]\tvalidation_0-rmse:0.71581\n",
      "[9999]\tvalidation_0-rmse:0.71422\n",
      "MSE: [0.716370745656987, 0.7237654879154056, 0.7196079078182203, 0.7192916067877397, 0.7142102739605147]\n",
      "Test data predictions:             id    pred_3\n",
      "0            0  8.099949\n",
      "1            5  8.381259\n",
      "2           15  8.411623\n",
      "3           16  8.506899\n",
      "4           17  8.168657\n",
      "...        ...       ...\n",
      "199995  499987  8.114617\n",
      "199996  499990  8.452845\n",
      "199997  499991  8.479716\n",
      "199998  499994  8.198995\n",
      "199999  499995  7.953298\n",
      "\n",
      "[200000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model_3 MSE and test_predictions\n",
    "mse_3, final_preds_3 = model_3()\n",
    "print(f\"MSE: {mse_3}\\nTest data predictions: {final_preds_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4128d8",
   "metadata": {
    "papermill": {
     "duration": 0.0417,
     "end_time": "2021-09-01T02:04:37.462926",
     "exception": false,
     "start_time": "2021-09-01T02:04:37.421226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading data from csv files\n",
    "* `train.csv`\n",
    "* `test.csv`\n",
    "* `sample_submission.csv`\n",
    "### Training predicted data\n",
    "* `train_pred_1.csv`\n",
    "* `train_pred_2.csv`\n",
    "* `train_pred_3.csv`\n",
    "### Test predicted data\n",
    "* `test_pred_1.csv`\n",
    "* `test_pred_2.csv`\n",
    "* `test_pred_3.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f43fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:04:37.553616Z",
     "iopub.status.busy": "2021-09-01T02:04:37.553064Z",
     "iopub.status.idle": "2021-09-01T02:04:40.188214Z",
     "shell.execute_reply": "2021-09-01T02:04:40.187359Z",
     "shell.execute_reply.started": "2021-09-01T01:33:30.218772Z"
    },
    "papermill": {
     "duration": 2.683709,
     "end_time": "2021-09-01T02:04:40.188363",
     "exception": false,
     "start_time": "2021-09-01T02:04:37.504654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/30-days-of-ml/train.csv\")\n",
    "test_data = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "train_pred_1 = pd.read_csv(\"train_preds_1.csv\")\n",
    "train_pred_2 = pd.read_csv(\"train_preds_2.csv\")\n",
    "train_pred_3 = pd.read_csv(\"train_preds_3.csv\")\n",
    "\n",
    "test_pred_1 = pd.read_csv(\"test_preds_1.csv\")\n",
    "test_pred_2 = pd.read_csv(\"test_preds_2.csv\")\n",
    "test_pred_3 = pd.read_csv(\"test_preds_3.csv\")\n",
    "\n",
    "train_data = train_data.merge(train_pred_1, on=\"id\", how=\"left\")\n",
    "train_data = train_data.merge(train_pred_2, on=\"id\", how=\"left\")\n",
    "train_data = train_data.merge(train_pred_3, on=\"id\", how=\"left\")\n",
    "\n",
    "test_data = pd.concat([test_data, test_pred_1, test_pred_2, test_pred_3], join=\"inner\", axis=1)\n",
    "test_data = test_data.drop(\"id\", axis=1)\n",
    "test_data[\"id\"] = test_pred_1[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d583c54",
   "metadata": {
    "papermill": {
     "duration": 0.042114,
     "end_time": "2021-09-01T02:04:40.273782",
     "exception": false,
     "start_time": "2021-09-01T02:04:40.231668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Getting useful features/columns from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1982575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:04:40.372939Z",
     "iopub.status.busy": "2021-09-01T02:04:40.372000Z",
     "iopub.status.idle": "2021-09-01T02:04:40.380331Z",
     "shell.execute_reply": "2021-09-01T02:04:40.380779Z",
     "shell.execute_reply.started": "2021-09-01T01:33:33.170677Z"
    },
    "papermill": {
     "duration": 0.06456,
     "end_time": "2021-09-01T02:04:40.380937",
     "exception": false,
     "start_time": "2021-09-01T02:04:40.316377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.090875</td>\n",
       "      <td>8.079402</td>\n",
       "      <td>8.099949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.369916</td>\n",
       "      <td>8.367846</td>\n",
       "      <td>8.381259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.402437</td>\n",
       "      <td>8.383591</td>\n",
       "      <td>8.411623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.499657</td>\n",
       "      <td>8.440797</td>\n",
       "      <td>8.506899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.180559</td>\n",
       "      <td>8.179073</td>\n",
       "      <td>8.168657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_1    pred_2    pred_3\n",
       "0  8.090875  8.079402  8.099949\n",
       "1  8.369916  8.367846  8.381259\n",
       "2  8.402437  8.383591  8.411623\n",
       "3  8.499657  8.440797  8.506899\n",
       "4  8.180559  8.179073  8.168657"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_cols = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
    "test_data = test_data[useful_cols]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556b331",
   "metadata": {
    "papermill": {
     "duration": 0.041899,
     "end_time": "2021-09-01T02:04:40.466891",
     "exception": false,
     "start_time": "2021-09-01T02:04:40.424992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final Model\n",
    "#### where:\n",
    "##### **K-fold** to split the training data(`train_dadta`) for training and testing\n",
    "##### **Target Encoding** to get numerical `median` values of categorical values\n",
    "##### **Linear Regression** to make the model and predict validation data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21334219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:04:40.557524Z",
     "iopub.status.busy": "2021-09-01T02:04:40.556665Z",
     "iopub.status.idle": "2021-09-01T02:04:40.608928Z",
     "shell.execute_reply": "2021-09-01T02:04:40.608436Z",
     "shell.execute_reply.started": "2021-09-01T01:33:39.933372Z"
    },
    "papermill": {
     "duration": 0.099597,
     "end_time": "2021-09-01T02:04:40.609053",
     "exception": false,
     "start_time": "2021-09-01T02:04:40.509456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# K-fold splitting where total folds = 5\n",
    "train_data[\"kfold\"] = -1\n",
    "Kf_model = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# fold (0, 1, 2, 3, 4); train_index (0, 2, 3...); valid_index(1, 4, 6)\n",
    "for fold, (train_index, valid_index) in enumerate(Kf_model.split(X=train_data)):\n",
    "    train_data.loc[valid_index, \"kfold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f9d719",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:04:40.705159Z",
     "iopub.status.busy": "2021-09-01T02:04:40.704206Z",
     "iopub.status.idle": "2021-09-01T02:04:41.506427Z",
     "shell.execute_reply": "2021-09-01T02:04:41.505494Z",
     "shell.execute_reply.started": "2021-09-01T01:33:41.638564Z"
    },
    "papermill": {
     "duration": 0.854637,
     "end_time": "2021-09-01T02:04:41.506687",
     "exception": false,
     "start_time": "2021-09-01T02:04:40.652050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, RMSE: 0.7162189975315332, \n",
      "Test predictions[8.09590519 8.3809012  8.41375117 ... 8.48379835 8.17324054 7.93478074]\n",
      "Fold: 1, RMSE: 0.7236446905520985, \n",
      "Test predictions[8.09601876 8.37985191 8.41227977 ... 8.48182613 8.17114252 7.93499532]\n",
      "Fold: 2, RMSE: 0.7194014916886058, \n",
      "Test predictions[8.09583753 8.38190605 8.41487582 ... 8.48520573 8.17506402 7.93483276]\n",
      "Fold: 3, RMSE: 0.7191667910948852, \n",
      "Test predictions[8.09404372 8.38094019 8.41438411 ... 8.48517472 8.17410287 7.93245189]\n",
      "Fold: 4, RMSE: 0.7139549511002987, \n",
      "Test predictions[8.09546049 8.38055705 8.4135681  ... 8.48378182 8.17604385 7.9355773 ]\n"
     ]
    }
   ],
   "source": [
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\"]\n",
    "test_data = test_data[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    X_train =  train_data[train_data.kfold != fold].reset_index(drop=True)\n",
    "    X_valid = train_data[train_data.kfold == fold].reset_index(drop=True)\n",
    "    X_test = test_data.copy()\n",
    "\n",
    "    y_train = X_train.target\n",
    "    y_valid = X_valid.target\n",
    "    \n",
    "    X_train = X_train[useful_features]\n",
    "    X_valid = X_valid[useful_features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    valid_preds = model.predict(X_valid)\n",
    "    test_preds = model.predict(X_test)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(y_valid, valid_preds, squared=False)\n",
    "    print(f\"Fold: {fold}, RMSE: {rmse}, \\nTest predictions{test_preds}\")\n",
    "    scores.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0583ad8d",
   "metadata": {
    "papermill": {
     "duration": 0.064366,
     "end_time": "2021-09-01T02:04:41.655889",
     "exception": false,
     "start_time": "2021-09-01T02:04:41.591523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submitting the Final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713e6b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-01T02:04:41.749059Z",
     "iopub.status.busy": "2021-09-01T02:04:41.747871Z",
     "iopub.status.idle": "2021-09-01T02:04:42.376846Z",
     "shell.execute_reply": "2021-09-01T02:04:42.376297Z",
     "shell.execute_reply.started": "2021-09-01T01:33:52.646606Z"
    },
    "papermill": {
     "duration": 0.677537,
     "end_time": "2021-09-01T02:04:42.376979",
     "exception": false,
     "start_time": "2021-09-01T02:04:41.699442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission.target = np.median(np.column_stack(final_predictions), axis=1)\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 653.80702,
   "end_time": "2021-09-01T02:04:44.038039",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-01T01:53:50.231019",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
